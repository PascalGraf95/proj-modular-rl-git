ddpg:
    BatchSize: 32
    Episodes: 1000000
    Epsilon: 0.25
    ExplorationParameters:
        Epsilon: 1
        EpsilonDecay: 0.995
        EpsilonMin: 0.01
    Gamma: 0.99
    LearningRateActor: 0.0001
    LearningRateCritic: 0.0001
    NSteps: 5
    NetworkParameters:
    -   Filters: 32
        Units: 100
        VectorNetworkArchitecture: Dense
        VisualNetworkArchitecture: CNN
    -   Filters: 32
        Units: 100
        VectorNetworkArchitecture: Dense
        VisualNetworkArchitecture: CNN
    ReplayCapacity: 100000
    ReplayMinSize: 1000
    SyncMode: soft_sync
    SyncSteps: 50
    Tau: 0.2
    TrainingID: DDPG2D
    TrainingInterval: 64
dqn:
    Recurrent: true
    BurnIn: 2
    AdaptiveSequenceLength: false
    ActionFeedback: false
    RewardFeedback: false
    PolicyFeedback: false
    SequenceLength: 10
    Overlap: 3
    ActorNum: 8
    ClipGrad: 10.0
    BatchSize: 32
    DoubleLearning: true
    AdaptiveExploration: true
    ExplorationParameters:
        Epsilon: 0.2
        EpsilonDecay: 0.9995
        EpsilonMin: 0.025
        StepDown: false
        FeatureSpaceSize: 18
        CuriosityScalingFactor: 0.01
        LearningRate: 0.00005
        ObservationNormalization: false
        kNearest: 10
        MaxIntRewardScaling: 0.3
        ClusterDistance: 0.008
        KernelEpsilon: 0.01
        MaximumSimilarity: 4
        EpisodicMemoryCapacity: 600
    Gamma: 0.99
    LearningRate: 0.0001
    NSteps: 5
    NetworkParameters:
        DuelingNetworks: true
        NoisyNetworks: false
        Filters: 16
        Units: 64
        VectorNetworkArchitecture: Dense
        VisualNetworkArchitecture: CNN
    NetworkUpdateFrequency: 50
    ReplayCapacity: 100000
    ReplayMinSize: 1000
    SyncMode: soft_sync
    SyncSteps: 200
    Tau: 0.01
    PrioritizedReplay: false
    PriorityAlpha: 0.8
    TrainingID: _debug_DQN_CartPole_TESTING
    TrainingInterval: 1

sac:
    Recurrent: true
    BurnIn: 0
    AdaptiveSequenceLength: false
    ActionFeedback: true
    RewardFeedback: true
    PolicyFeedback: true
    SequenceLength: 12
    Overlap: 6
    ActorNum: 8
    BatchSize: 32
    ClipGrad: 10.0
    ExplorationParameters:
        FeatureSpaceSize: 18
        CuriosityScalingFactor: 0.03
        LearningRate: 0.00005
        Epsilon: 0.25
        EpsilonDecay: 0.9995
        EpsilonMin: 0.01
        StepDown: false
        ObservationNormalization: false
        kNearest: 10
        MaxIntRewardScaling: 0.3
        ClusterDistance: 0.008
        KernelEpsilon: 0.01
        MaximumSimilarity: 4
        EpisodicMemoryCapacity: 600
    Gamma: 0.99
    LearningRateActor: 0.0005
    LearningRateCritic: 0.0005
    LogAlpha: -4.0
    NSteps: 4
    AdaptiveExploration: false
    NetworkUpdateFrequency: 50
    SelfPlayNetworkUpdateFrequency: 100000
    NetworkParameters:
        Filters: 16
        Units: 64
        ActorVectorNetworkArchitecture: Dense
        ActorVisualNetworkArchitecture: CNN
        CriticVectorNetworkArchitecture: Dense
        CriticVisualNetworkArchitecture: CNN
    PrioritizedReplay: true
    PriorityAlpha: 0.75
    RewardNormalization: false
    ReplayCapacity: 100000
    ReplayMinSize: 100
    SyncMode: soft_sync
    SyncSteps: 500
    Tau: 0.01
    TrainingID: SAC_Airhockey_Selfplay_TFTEST
    TrainingInterval: 10
cql:
    Recurrent: false
    BurnIn: 0
    AdaptiveSequenceLength: false
    SequenceLength: 30
    Overlap: 8
    ActorNum: 1
    BatchSize: 256
    ClipGrad: 10.0
    ExplorationParameters:
        FeatureSpaceSize: 16
        CuriosityScalingFactor: 0.02
        LearningRate: 0.001
        Epsilon: 0.99
        EpsilonDecay: 0.9995
        EpsilonMin: 0.01
        StepDown: false
    Gamma: 0.99
    LearningRateActor: 0.00003
    LearningRateCritic: 0.0005
    CQLTemperature: 10.0
    CQLWeight: 1.0
    LogAlpha: -4.0
    NSteps: 4
    AdaptiveExploration: true
    NetworkUpdateFrequency: 50
    SelfPlayNetworkUpdateFrequency: 1000
    NetworkParameters:
        Filters: 16
        Units: 64
        ActorVectorNetworkArchitecture: Dense
        ActorVisualNetworkArchitecture: CNN
        CriticVectorNetworkArchitecture: Dense
        CriticVisualNetworkArchitecture: CNN
    PrioritizedReplay: false
    PriorityAlpha: 0.8
    RewardNormalization: false
    ReplayCapacity: 1000000
    ReplayMinSize: 100
    SyncMode: soft_sync
    SyncSteps: 500
    Tau: 0.01
    TrainingID: CQL_SinglePendulum
    TrainingInterval: 1
td3:
    ActorTrainingFreq: 3
    BatchSize: 64
    ClipGrad: 10.0
    Episodes: 1000000
    Epsilon: 0.2
    ExplorationParameters:
        Epsilon: 1.0
        EpsilonDecay: 0.9995
        EpsilonMin: 0.03
        StepDown: 0
    Gamma: 0.99
    LearningRateActor: 0.001
    LearningRateCritic: 0.001
    NSteps: 4
    NetworkParameters:
    -   Filters: 64
        Units: 64
        VectorNetworkArchitecture: Dense
        VisualNetworkArchitecture: CNN
    -   Filters: 32
        Units: 32
        VectorNetworkArchitecture: Dense
        VisualNetworkArchitecture: CNN
    -   Filters: 32
        Units: 32
        VectorNetworkArchitecture: Dense
        VisualNetworkArchitecture: CNN
    PredictionNoise: 0.2
    PredictionNoiseClip: 0.5
    PrioritizedReplay: false
    ReplayCapacity: 100000
    ReplayMinSize: 5000
    SyncMode: soft_sync
    SyncSteps: 50
    Tau: 0.04
    TrainingID: TD3_3DBall
    TrainingInterval: 64
